{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# changing core directory\n",
        "import os, sys\n",
        "dir2 = os.path.abspath('')\n",
        "dir1 = os.path.dirname(dir2)\n",
        "if not dir1 in sys.path:\n",
        "    sys.path.append(dir1)\n",
        "os.chdir('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fjZ8TtF8mKQ6"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import ndcg_score\n",
        "import lightgbm as lgb\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "from src.data import load_data, download_movielens1m, ValSASRecDataset, TrainSASRecDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 0\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fix_seed(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "fix_seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiq6wFeEnPCo"
      },
      "source": [
        "# Подгрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7-jDCcbhmNk8"
      },
      "outputs": [],
      "source": [
        "# # Скачивание и распаковка датасета\n",
        "# def download_movielens1m():\n",
        "#     url = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
        "#     if not os.path.exists(\"ml-1m\"):\n",
        "#         print(\"Downloading MovieLens 1M dataset...\")\n",
        "#         response = requests.get(url, stream=True)\n",
        "#         with open(\"ml-1m.zip\", \"wb\") as f:\n",
        "#             for chunk in response.iter_content(chunk_size=1024):\n",
        "#                 if chunk:\n",
        "#                     f.write(chunk)\n",
        "\n",
        "#         with zipfile.ZipFile(\"ml-1m.zip\", 'r') as zip_ref:\n",
        "#             zip_ref.extractall(\".\")\n",
        "#         print(\"Dataset downloaded and extracted.\")\n",
        "#     else:\n",
        "#         print(\"Dataset already exists.\")\n",
        "\n",
        "# # Загрузка данных\n",
        "# def load_data():\n",
        "#     ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', engine='python',\n",
        "#                          names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
        "#     ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
        "#     return ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QdgWFOUmQnd",
        "outputId": "1ddbecea-3525-4c67-befb-c4776ccbc05c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists.\n"
          ]
        }
      ],
      "source": [
        "# Скачиваем и загружаем данные\n",
        "download_movielens1m()\n",
        "ratings = load_data()\n",
        "\n",
        "ratings = ratings[ratings[\"rating\"] > 3.5]\n",
        "\n",
        "# Подготовка данных\n",
        "num_users = ratings['user_id'].nunique()\n",
        "num_items = ratings['item_id'].nunique()\n",
        "\n",
        "user2id = {val:i for i, val in enumerate(ratings['user_id'].unique())}\n",
        "item2id = {val:i+1 for i, val in enumerate(ratings['item_id'].unique())}\n",
        "\n",
        "ratings['user_id'] = ratings['user_id'].map(user2id)\n",
        "ratings['item_id'] = ratings['item_id'].map(item2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NSrn6M5mVF-",
        "outputId": "a8d30a89-c0f2-4f18-a543-7405c7882872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4830 1208\n"
          ]
        }
      ],
      "source": [
        "# Создаем последовательности\n",
        "sequences = []\n",
        "times = []\n",
        "for user_id, group in ratings.groupby('user_id'):\n",
        "    group = group.sort_values('timestamp')\n",
        "    user_seq = group['item_id'].tolist()\n",
        "    user_times = group['timestamp'].astype(int).tolist()\n",
        "    sequences.append(user_seq)\n",
        "    times.append(user_times)\n",
        "\n",
        "# Разделяем на train/val\n",
        "split_idx = int(0.8 * len(sequences))\n",
        "train_sequences = sequences[:split_idx]\n",
        "val_sequences = sequences[split_idx:]\n",
        "\n",
        "train_times = times[:split_idx]\n",
        "val_times = times[split_idx:]\n",
        "\n",
        "all_users = ratings['user_id'].unique()\n",
        "train_users, val_users = all_users[:split_idx], all_users[split_idx:]\n",
        "print(len(train_users), len(val_users))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umenI8xbnR3j"
      },
      "source": [
        "# Обучение нейронки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aAOIKGbTmXlo"
      },
      "outputs": [],
      "source": [
        "# Создание датасета для SASRec\n",
        "\n",
        "# class TrainSASRecDataset(Dataset):\n",
        "#     def __init__(self, sequences, times, max_len=50):\n",
        "#         self.sequences = sequences\n",
        "#         self.times = times\n",
        "#         self.max_len = max_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sequences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         seq = self.sequences[idx]\n",
        "#         time = self.times[idx]\n",
        "#         if len(seq) > self.max_len:\n",
        "#             seq = seq[-self.max_len:]\n",
        "#             time = time[-self.max_len:]\n",
        "#         else:\n",
        "#             seq = [0] * (self.max_len - len(seq)) + seq\n",
        "#             time = [0] * (self.max_len - len(time)) + time\n",
        "#         input_seq = torch.tensor(seq[:-1], dtype=torch.long)\n",
        "#         input_times = torch.tensor(time[:-1], dtype=torch.long)\n",
        "#         target = torch.tensor(seq[1:], dtype=torch.long)\n",
        "#         return (input_seq, input_times), target\n",
        "\n",
        "\n",
        "# class ValSASRecDataset(Dataset):\n",
        "#     def __init__(self, sequences, times, max_len=50):\n",
        "#         self.sequences = sequences\n",
        "#         self.times = times\n",
        "#         self.max_len = max_len\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sequences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         seq = self.sequences[idx]\n",
        "#         time = self.times[idx]\n",
        "#         if len(seq) > self.max_len:\n",
        "#             seq = seq[-self.max_len:]\n",
        "#             time = time[-self.max_len:]\n",
        "#         else:\n",
        "#             seq = [0] * (self.max_len - len(seq)) + seq\n",
        "#             time = [0] * (self.max_len - len(time)) + time\n",
        "#         input_seq = torch.tensor(seq[:-1], dtype=torch.long)\n",
        "#         input_times = torch.tensor(time[:-1], dtype=torch.long)\n",
        "#         target = torch.tensor(seq[-1], dtype=torch.long)\n",
        "\n",
        "#         return (input_seq, input_times), target\n",
        "\n",
        "\n",
        "max_len = 200\n",
        "train_dataset = TrainSASRecDataset(train_sequences, train_times, max_len)\n",
        "val_dataset = ValSASRecDataset(val_sequences, val_times, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RlWAVuZjmeMd"
      },
      "outputs": [],
      "source": [
        "# Модель SASRec на PyTorch\n",
        "class SASRec(nn.Module):\n",
        "    def __init__(self,\n",
        "        num_items,\n",
        "        hidden_units=64,\n",
        "        num_heads=2,\n",
        "        num_blocks=2,\n",
        "        dropout_rate=0.2,\n",
        "        max_len=200,\n",
        "        ext_flag=False\n",
        "    ):\n",
        "        super(SASRec, self).__init__()\n",
        "        self.num_items = num_items\n",
        "        self.hidden_units = hidden_units\n",
        "        self.max_len = max_len\n",
        "        self.ext_flag = ext_flag\n",
        "\n",
        "        self.item_emb = nn.Embedding(num_items + 1, hidden_units, padding_idx=0)\n",
        "        self.pos_emb = nn.Embedding(max_len, hidden_units)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=hidden_units,\n",
        "                nhead=num_heads,\n",
        "                dim_feedforward=hidden_units,\n",
        "                dropout=dropout_rate,\n",
        "                batch_first=True\n",
        "            ) for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_units)\n",
        "        self.output_layer = nn.Linear(hidden_units, num_items + 1)\n",
        "\n",
        "    def forward(self, input_seqs, timestamps=None):\n",
        "        batch_size, seq_len = input_seqs.size()\n",
        "\n",
        "        # Position encoding\n",
        "        positions = torch.arange(seq_len, dtype=torch.long, device=input_seqs.device)\n",
        "        positions = positions.unsqueeze(0).expand(batch_size, seq_len)\n",
        "\n",
        "        # Item and position embedding\n",
        "        item_emb = self.item_emb(input_seqs)\n",
        "        pos_emb = self.pos_emb(positions)\n",
        "        x = item_emb + pos_emb\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Transformer encoder\n",
        "        mask = self.generate_square_subsequent_mask(seq_len).to(input_seqs.device)\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        if self.ext_flag:\n",
        "            ext_context = self.get_external_features(timestamps).to(x.device)\n",
        "            extended_data = torch.cat([x, ext_context], dim=2)\n",
        "            output = self.ext_head(extended_data)\n",
        "        else:\n",
        "            output = self.output_layer(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def get_embeddings(self, input_seqs):\n",
        "        batch_size, seq_len = input_seqs.size()\n",
        "\n",
        "        positions = torch.arange(seq_len, dtype=torch.long, device=input_seqs.device)\n",
        "        positions = positions.unsqueeze(0).expand(batch_size, seq_len)\n",
        "\n",
        "        item_emb = self.item_emb(input_seqs)\n",
        "        pos_emb = self.pos_emb(positions)\n",
        "        x = item_emb + pos_emb\n",
        "\n",
        "        mask = self.generate_square_subsequent_mask(seq_len).to(input_seqs.device)\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "        return x\n",
        "\n",
        "    def freeze(self):\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "        print(\"Все слои сети заморожены.\")\n",
        "\n",
        "    def add_external_features(self, ext_features):\n",
        "        self.ext_flag = True\n",
        "        self.freeze()\n",
        "        self.ext_head = nn.Linear(self.hidden_units*2, num_items + 1)\n",
        "        self.time_list = ext_features[0]\n",
        "        self.ext_embeddings = ext_features[1]\n",
        "\n",
        "    def get_external_features(self, timestamps):\n",
        "        bs, seq_len = timestamps.shape\n",
        "        timestamps = timestamps.reshape(-1).cpu().detach().numpy()\n",
        "\n",
        "        ext_ids = np.searchsorted(self.time_list, timestamps, side='right') - 1\n",
        "        ext_context = self.ext_embeddings[ext_ids]\n",
        "        ext_context = torch.tensor(ext_context, dtype=torch.float32).reshape(bs, seq_len, -1)\n",
        "        return ext_context\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # def add_external_features(self, ext_features):\n",
        "    #     self.ext_flag = True\n",
        "    #     self.freeze()\n",
        "    #     self.ext_head = nn.Linear(self.hidden_units*2, num_items + 1)\n",
        "    #     self.ext_features = ext_features\n",
        "    #     self.ext_features['timestamp'] = self.ext_features['timestamp'].astype(int)\n",
        "\n",
        "    # def get_external_features(self, timestamps):\n",
        "    #     bs, seq_len = timestamps.shape\n",
        "    #     timestamps = timestamps.reshape(-1)\n",
        "    #     ext_context = []\n",
        "    #     for time in timestamps:\n",
        "    #         ext_context.append(self.get_one_ext_represent(time))\n",
        "\n",
        "    #     ext_context = torch.tensor(ext_context, dtype=torch.float32)\n",
        "    #     ext_context = ext_context.reshape(bs, seq_len, -1)\n",
        "    #     return ext_context\n",
        "\n",
        "    # def get_one_ext_represent(self, time):\n",
        "    #     context_info = self.ext_features[self.ext_features['timestamp'] <= time.cpu().detach().numpy()]\n",
        "    #     if len(context_info) > 0:\n",
        "    #         context_info = context_info.iloc[-1]\n",
        "    #         mean_context = context_info['mean_embedding']\n",
        "    #         return mean_context\n",
        "    #     else:\n",
        "    #         return np.zeros(self.hidden_units)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fKdRlSyFme6z"
      },
      "outputs": [],
      "source": [
        "def calculate_ndcg(model, dataloader, device, k=10):\n",
        "    model.eval()\n",
        "\n",
        "    # Вместо накопления всех предсказаний, будем вычислять NDCG по батчам\n",
        "    ndcg_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (input_seqs, input_times), targets in dataloader:\n",
        "            input_seqs, input_times, targets = input_seqs.to(device), input_times.to(device), targets.to(device)\n",
        "            outputs = model(input_seqs, input_times)\n",
        "            last_outputs = outputs[:, -1, :]\n",
        "\n",
        "            # Преобразуем в numpy\n",
        "            predictions = last_outputs.cpu().numpy()\n",
        "            targets_np = targets.cpu().numpy()\n",
        "\n",
        "            # Создаем матрицу релевантности только для текущего батча\n",
        "            n_items = predictions.shape[1]\n",
        "            relevance = np.zeros((len(targets_np), n_items))\n",
        "            relevance[np.arange(len(targets_np)), targets_np] = 1\n",
        "\n",
        "            # Вычисляем NDCG для текущего батча\n",
        "            try:\n",
        "                batch_ndcg = ndcg_score(relevance, predictions, k=k)\n",
        "                ndcg_scores.append(batch_ndcg)\n",
        "            except MemoryError:\n",
        "                # Если батч слишком большой, разбиваем его на подбатчи\n",
        "                sub_batch_size = 100\n",
        "                for i in range(0, len(targets_np), sub_batch_size):\n",
        "                    end_idx = min(i + sub_batch_size, len(targets_np))\n",
        "                    sub_relevance = relevance[i:end_idx]\n",
        "                    sub_predictions = predictions[i:end_idx]\n",
        "                    sub_ndcg = ndcg_score(sub_relevance, sub_predictions, k=k)\n",
        "                    ndcg_scores.append(sub_ndcg)\n",
        "\n",
        "    # Возвращаем среднее значение NDCG по всем батчам\n",
        "    return np.mean(ndcg_scores)\n",
        "\n",
        "# Обучение модели SASRec\n",
        "def train_sasrec(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n",
        "    model.to(device)\n",
        "    best_ndcg = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch_idx, ((input_seqs, input_times), targets) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
        "            input_seqs, input_times, targets = input_seqs.to(device), input_times.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_seqs, input_times)\n",
        "\n",
        "            # Получаем предсказания для последнего элемента в последовательности\n",
        "            # last_outputs = outputs[:, -1, :]\n",
        "            #loss = criterion(last_outputs, targets)\n",
        "            outputs, targets = outputs.reshape(-1, num_items+1), targets.reshape(-1)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Валидация\n",
        "        val_ndcg = calculate_ndcg(model, val_loader, device)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}, Val NDCG@{10}: {val_ndcg:.4f}\")\n",
        "\n",
        "        # Сохраняем лучшую модель\n",
        "        if val_ndcg > best_ndcg:\n",
        "            best_ndcg = val_ndcg\n",
        "            torch.save(model.state_dict(), \"best_sasrec_model.pth\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B1shKWHmlvi",
        "outputId": "982e1b6d-03d0-427b-9684-b769b409587a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/70: 100%|██████████| 38/38 [00:10<00:00,  3.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 5.3168, Val NDCG@10: 0.0066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/70: 100%|██████████| 38/38 [00:10<00:00,  3.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 3.6244, Val NDCG@10: 0.0076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/70: 100%|██████████| 38/38 [00:13<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 3.4732, Val NDCG@10: 0.0070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/70: 100%|██████████| 38/38 [00:11<00:00,  3.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 3.1314, Val NDCG@10: 0.0095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/70: 100%|██████████| 38/38 [00:13<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 3.0233, Val NDCG@10: 0.0120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/70: 100%|██████████| 38/38 [00:16<00:00,  2.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 2.9959, Val NDCG@10: 0.0131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/70: 100%|██████████| 38/38 [00:09<00:00,  4.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 2.9791, Val NDCG@10: 0.0124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/70: 100%|██████████| 38/38 [00:14<00:00,  2.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 2.9688, Val NDCG@10: 0.0105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/70: 100%|██████████| 38/38 [00:13<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 2.9562, Val NDCG@10: 0.0110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/70: 100%|██████████| 38/38 [00:12<00:00,  3.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 2.9502, Val NDCG@10: 0.0112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/70: 100%|██████████| 38/38 [00:12<00:00,  3.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Loss: 2.9421, Val NDCG@10: 0.0105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/70: 100%|██████████| 38/38 [00:06<00:00,  5.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Loss: 2.9353, Val NDCG@10: 0.0130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/70: 100%|██████████| 38/38 [00:11<00:00,  3.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Loss: 2.9302, Val NDCG@10: 0.0131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/70: 100%|██████████| 38/38 [00:14<00:00,  2.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Loss: 2.9271, Val NDCG@10: 0.0121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/70: 100%|██████████| 38/38 [00:13<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Loss: 2.9223, Val NDCG@10: 0.0141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/70: 100%|██████████| 38/38 [00:12<00:00,  3.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Loss: 2.9182, Val NDCG@10: 0.0128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/70: 100%|██████████| 38/38 [00:12<00:00,  3.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Loss: 2.9158, Val NDCG@10: 0.0132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/70: 100%|██████████| 38/38 [00:16<00:00,  2.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Loss: 2.9088, Val NDCG@10: 0.0146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/70: 100%|██████████| 38/38 [00:14<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Loss: 2.9034, Val NDCG@10: 0.0163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/70: 100%|██████████| 38/38 [00:13<00:00,  2.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Loss: 2.8967, Val NDCG@10: 0.0156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/70: 100%|██████████| 38/38 [00:07<00:00,  4.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, Loss: 2.8831, Val NDCG@10: 0.0180\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/70: 100%|██████████| 38/38 [00:16<00:00,  2.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22, Loss: 2.8715, Val NDCG@10: 0.0219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/70: 100%|██████████| 38/38 [00:10<00:00,  3.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23, Loss: 2.8528, Val NDCG@10: 0.0249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/70: 100%|██████████| 38/38 [00:11<00:00,  3.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24, Loss: 2.8341, Val NDCG@10: 0.0250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/70: 100%|██████████| 38/38 [00:13<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25, Loss: 2.8173, Val NDCG@10: 0.0258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/70: 100%|██████████| 38/38 [00:08<00:00,  4.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26, Loss: 2.7908, Val NDCG@10: 0.0277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/70: 100%|██████████| 38/38 [00:13<00:00,  2.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27, Loss: 2.7704, Val NDCG@10: 0.0317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/70: 100%|██████████| 38/38 [00:15<00:00,  2.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28, Loss: 2.7538, Val NDCG@10: 0.0323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/70: 100%|██████████| 38/38 [00:09<00:00,  4.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29, Loss: 2.7327, Val NDCG@10: 0.0336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/70: 100%|██████████| 38/38 [00:17<00:00,  2.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30, Loss: 2.7196, Val NDCG@10: 0.0353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/70: 100%|██████████| 38/38 [00:15<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31, Loss: 2.7061, Val NDCG@10: 0.0380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/70: 100%|██████████| 38/38 [00:15<00:00,  2.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32, Loss: 2.6877, Val NDCG@10: 0.0409\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/70: 100%|██████████| 38/38 [00:13<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33, Loss: 2.6747, Val NDCG@10: 0.0396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/70: 100%|██████████| 38/38 [00:11<00:00,  3.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34, Loss: 2.6574, Val NDCG@10: 0.0419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/70: 100%|██████████| 38/38 [00:11<00:00,  3.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35, Loss: 2.6473, Val NDCG@10: 0.0404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/70: 100%|██████████| 38/38 [00:19<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36, Loss: 2.6302, Val NDCG@10: 0.0423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/70: 100%|██████████| 38/38 [00:14<00:00,  2.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37, Loss: 2.6192, Val NDCG@10: 0.0436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/70: 100%|██████████| 38/38 [00:13<00:00,  2.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38, Loss: 2.6050, Val NDCG@10: 0.0439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/70: 100%|██████████| 38/38 [00:19<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39, Loss: 2.5920, Val NDCG@10: 0.0461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/70: 100%|██████████| 38/38 [00:09<00:00,  3.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40, Loss: 2.5782, Val NDCG@10: 0.0460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/70: 100%|██████████| 38/38 [00:16<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41, Loss: 2.5678, Val NDCG@10: 0.0487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/70: 100%|██████████| 38/38 [00:18<00:00,  2.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42, Loss: 2.5580, Val NDCG@10: 0.0495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/70: 100%|██████████| 38/38 [00:16<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43, Loss: 2.5451, Val NDCG@10: 0.0513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/70: 100%|██████████| 38/38 [00:07<00:00,  5.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44, Loss: 2.5347, Val NDCG@10: 0.0522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/70: 100%|██████████| 38/38 [00:12<00:00,  3.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45, Loss: 2.5252, Val NDCG@10: 0.0544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/70: 100%|██████████| 38/38 [00:14<00:00,  2.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46, Loss: 2.5153, Val NDCG@10: 0.0551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/70: 100%|██████████| 38/38 [00:08<00:00,  4.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47, Loss: 2.5049, Val NDCG@10: 0.0544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/70: 100%|██████████| 38/38 [00:16<00:00,  2.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48, Loss: 2.4983, Val NDCG@10: 0.0561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/70: 100%|██████████| 38/38 [00:19<00:00,  1.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49, Loss: 2.4902, Val NDCG@10: 0.0567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/70: 100%|██████████| 38/38 [00:16<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50, Loss: 2.4813, Val NDCG@10: 0.0551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 51/70: 100%|██████████| 38/38 [00:15<00:00,  2.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51, Loss: 2.4742, Val NDCG@10: 0.0573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 52/70: 100%|██████████| 38/38 [00:10<00:00,  3.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52, Loss: 2.4689, Val NDCG@10: 0.0595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 53/70: 100%|██████████| 38/38 [00:14<00:00,  2.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53, Loss: 2.4615, Val NDCG@10: 0.0610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 54/70: 100%|██████████| 38/38 [00:11<00:00,  3.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54, Loss: 2.4574, Val NDCG@10: 0.0607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 55/70: 100%|██████████| 38/38 [00:12<00:00,  2.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55, Loss: 2.4512, Val NDCG@10: 0.0620\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 56/70: 100%|██████████| 38/38 [00:12<00:00,  3.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56, Loss: 2.4449, Val NDCG@10: 0.0614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 57/70: 100%|██████████| 38/38 [00:15<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57, Loss: 2.4374, Val NDCG@10: 0.0627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 58/70: 100%|██████████| 38/38 [00:18<00:00,  2.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58, Loss: 2.4340, Val NDCG@10: 0.0642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 59/70: 100%|██████████| 38/38 [00:01<00:00, 31.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59, Loss: 2.4297, Val NDCG@10: 0.0624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 60/70: 100%|██████████| 38/38 [00:14<00:00,  2.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60, Loss: 2.4210, Val NDCG@10: 0.0634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 61/70: 100%|██████████| 38/38 [00:11<00:00,  3.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61, Loss: 2.4179, Val NDCG@10: 0.0620\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 62/70: 100%|██████████| 38/38 [00:15<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62, Loss: 2.4151, Val NDCG@10: 0.0626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 63/70: 100%|██████████| 38/38 [00:12<00:00,  2.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63, Loss: 2.4092, Val NDCG@10: 0.0649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 64/70: 100%|██████████| 38/38 [00:12<00:00,  3.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64, Loss: 2.4029, Val NDCG@10: 0.0656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 65/70: 100%|██████████| 38/38 [00:08<00:00,  4.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65, Loss: 2.4014, Val NDCG@10: 0.0648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 66/70: 100%|██████████| 38/38 [00:07<00:00,  5.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66, Loss: 2.3941, Val NDCG@10: 0.0626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 67/70: 100%|██████████| 38/38 [00:14<00:00,  2.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67, Loss: 2.3910, Val NDCG@10: 0.0643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 68/70: 100%|██████████| 38/38 [00:15<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68, Loss: 2.3892, Val NDCG@10: 0.0653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 69/70: 100%|██████████| 38/38 [00:19<00:00,  1.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69, Loss: 2.3853, Val NDCG@10: 0.0661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 70/70: 100%|██████████| 38/38 [00:19<00:00,  1.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70, Loss: 2.3791, Val NDCG@10: 0.0676\n"
          ]
        }
      ],
      "source": [
        "# Инициализируем модель\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SASRec(num_items, max_len=max_len).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# # Обучаем модель\n",
        "model = train_sasrec(model, train_loader, val_loader, optimizer, criterion, device, epochs=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePSHAAFAmn71",
        "outputId": "aded20ee-4701-481b-bee3-161a7df882ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загружаем лучшую модель\n",
        "model.load_state_dict(torch.load(\"best_sasrec_model.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr0y4JTknWaA"
      },
      "source": [
        "# Аггрегации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB5yc5gWnZT-",
        "outputId": "252dc037-3724-4cdc-a55f-a8821e0d1a07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загружаем лучшую модель\n",
        "model.load_state_dict(torch.load(\"best_sasrec_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K6TCxuB7nbQQ"
      },
      "outputs": [],
      "source": [
        "# n_ext_users = 100 # Выбираем 100 случайных пользователей\n",
        "\n",
        "# user_subset = np.random.choice(train_users, n_ext_users, replace=False)\n",
        "# subset_data = ratings[ratings['user_id'].isin(user_subset)].sort_values(['user_id', 'timestamp'])\n",
        "\n",
        "# # Создаем словарь для хранения эмбеддингов пользователей по времени\n",
        "# user_embeddings = defaultdict(list)\n",
        "\n",
        "# # Получаем эмбеддинги для каждого пользователя в каждый момент времени\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     for user_id in tqdm(user_subset, desc=\"Processing users\"):\n",
        "#         user_data = subset_data[subset_data['user_id'] == user_id]\n",
        "#         user_items = user_data['item_id'].tolist()\n",
        "\n",
        "#         for i in range(1, len(user_items) + 1):\n",
        "#             seq = user_items[:i]\n",
        "#             if len(seq) > model.max_len:\n",
        "#                 seq = seq[-model.max_len:]\n",
        "#             else:\n",
        "#                 seq = [0] * (model.max_len - len(seq)) + seq\n",
        "\n",
        "#             input_seq = torch.tensor([seq], dtype=torch.long).to(device)\n",
        "#             embeddings = model.get_embeddings(input_seq)\n",
        "\n",
        "#             # Берем последний эмбеддинг (для последнего элемента в последовательности)\n",
        "#             last_embedding = embeddings[0, -1, :].cpu().numpy()\n",
        "#             timestamp = user_data.iloc[i-1]['timestamp']\n",
        "\n",
        "#             user_embeddings[user_id].append((timestamp, last_embedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lshUPRuWakoV",
        "outputId": "aae906cc-7344-4244-be91-0db5592e492a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing users:   0%|          | 0/500 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing users: 100%|██████████| 500/500 [02:05<00:00,  3.97it/s]\n"
          ]
        }
      ],
      "source": [
        "n_ext_users = 500 # Выбираем 100 случайных пользователей\n",
        "\n",
        "user_subset = np.random.choice(train_users, n_ext_users, replace=False)\n",
        "subset_data = ratings[ratings['user_id'].isin(user_subset)].sort_values(['user_id', 'timestamp'])\n",
        "\n",
        "# Создаем словарь для хранения эмбеддингов пользователей по времени\n",
        "user_embeddings = defaultdict(list)\n",
        "\n",
        "# Получаем эмбеддинги для каждого пользователя в каждый момент времени\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for user_id in tqdm(user_subset, desc=\"Processing users\"):\n",
        "        user_data = subset_data[subset_data['user_id'] == user_id]\n",
        "        user_items = user_data['item_id'].tolist()\n",
        "        timestamps = user_data['timestamp'].astype(int).tolist()\n",
        "\n",
        "        if len(user_items) <= model.max_len:\n",
        "            seq = [0] * (model.max_len - len(user_items)) + user_items\n",
        "            input_seq = torch.tensor([seq], dtype=torch.long).to(device)\n",
        "            embeddings = model.get_embeddings(input_seq).cpu().numpy()[0, :, :]\n",
        "\n",
        "        else:\n",
        "            for i in range(0, len(user_items) + 1, model.max_len):\n",
        "                seq = user_items[i:model.max_len + i]\n",
        "                input_seq = torch.tensor([seq], dtype=torch.long).to(device)\n",
        "                batch_emb = model.get_embeddings(input_seq).cpu().numpy()[0, :, :]\n",
        "                if i > 0:\n",
        "                    embeddings = np.concatenate([embeddings, batch_emb], axis=0)\n",
        "                else:\n",
        "                    embeddings = batch_emb\n",
        "\n",
        "        for time, embed in zip(timestamps, embeddings):\n",
        "                user_embeddings[user_id].append((time, embed))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTtLpSioi_u4",
        "outputId": "093d8623-0c1f-4ef2-91e6-fb5c3382f86b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Aggregating embeddings: 100%|██████████| 27283/27283 [01:17<00:00, 352.68it/s]\n"
          ]
        }
      ],
      "source": [
        "# Агрегируем эмбеддинги по времени\n",
        "def aggregate_embeddings(embeddings_list, method='mean'):\n",
        "    if not embeddings_list:\n",
        "        return np.zeros(model.hidden_units)\n",
        "\n",
        "    embeddings = np.array([emb[1] for emb in embeddings_list])\n",
        "    if method == 'mean':\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    elif method == 'max':\n",
        "        return np.max(embeddings, axis=0)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown aggregation method: {method}\")\n",
        "\n",
        "# Создаем таблицу с агрегированными эмбеддингами по времени\n",
        "all_timestamps = sorted(set([ts for user_embs in user_embeddings.values() for ts, _ in user_embs]))\n",
        "\n",
        "\n",
        "aggregated_embeddings = []\n",
        "\n",
        "for timestamp in tqdm(all_timestamps, desc=\"Aggregating embeddings\"):\n",
        "    # Собираем последние эмбеддинги для каждого пользователя на данный момент времени\n",
        "    current_embeddings = []\n",
        "    for user_id, embeddings_list in user_embeddings.items():\n",
        "        # Находим последний эмбеддинг пользователя до данного времени\n",
        "        user_embs_before = [(ts, emb) for ts, emb in embeddings_list if ts <= timestamp]\n",
        "        if user_embs_before:\n",
        "            # Берем последний эмбеддинг\n",
        "            last_emb = user_embs_before[-1][1]\n",
        "            current_embeddings.append(last_emb)\n",
        "\n",
        "    # Агрегируем эмбеддинги всех пользователей\n",
        "    if current_embeddings:\n",
        "        mean_agg = aggregate_embeddings([(timestamp, emb) for emb in current_embeddings], 'mean')\n",
        "        max_agg = aggregate_embeddings([(timestamp, emb) for emb in current_embeddings], 'max')\n",
        "\n",
        "        aggregated_embeddings.append({\n",
        "            'timestamp': timestamp,\n",
        "            'mean_embedding': mean_agg,\n",
        "            'max_embedding': max_agg\n",
        "        })\n",
        "\n",
        "# Создаем DataFrame с агрегированными эмбеддингами\n",
        "agg_emb_df = pd.DataFrame(aggregated_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EIjoyyTPnhsw",
        "outputId": "42752dc9-3c39-4ea8-fb0f-ebb9007444a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>mean_embedding</th>\n",
              "      <th>max_embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>962905362000000000</td>\n",
              "      <td>[-1.1905193, -1.9180659, -1.3795913, -1.266162...</td>\n",
              "      <td>[-1.1905193, -1.9180659, -1.3795913, -1.266162...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>962905391000000000</td>\n",
              "      <td>[-1.133453, -2.39427, -1.4291996, -0.7620805, ...</td>\n",
              "      <td>[-1.133453, -2.39427, -1.4291996, -0.7620805, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>962905432000000000</td>\n",
              "      <td>[-1.5036978, -2.384849, -1.2538649, -0.8103050...</td>\n",
              "      <td>[-1.5036978, -2.384849, -1.2538649, -0.8103050...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>962905482000000000</td>\n",
              "      <td>[-1.3773258, -2.294885, -1.415181, -1.0748416,...</td>\n",
              "      <td>[-1.3773258, -2.294885, -1.415181, -1.0748416,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>962905586000000000</td>\n",
              "      <td>[-1.4487029, -2.2257712, -1.1753342, -1.394096...</td>\n",
              "      <td>[-1.4487029, -2.2257712, -1.1753342, -1.394096...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            timestamp                                     mean_embedding  \\\n",
              "0  962905362000000000  [-1.1905193, -1.9180659, -1.3795913, -1.266162...   \n",
              "1  962905391000000000  [-1.133453, -2.39427, -1.4291996, -0.7620805, ...   \n",
              "2  962905432000000000  [-1.5036978, -2.384849, -1.2538649, -0.8103050...   \n",
              "3  962905482000000000  [-1.3773258, -2.294885, -1.415181, -1.0748416,...   \n",
              "4  962905586000000000  [-1.4487029, -2.2257712, -1.1753342, -1.394096...   \n",
              "\n",
              "                                       max_embedding  \n",
              "0  [-1.1905193, -1.9180659, -1.3795913, -1.266162...  \n",
              "1  [-1.133453, -2.39427, -1.4291996, -0.7620805, ...  \n",
              "2  [-1.5036978, -2.384849, -1.2538649, -0.8103050...  \n",
              "3  [-1.3773258, -2.294885, -1.415181, -1.0748416,...  \n",
              "4  [-1.4487029, -2.2257712, -1.1753342, -1.394096...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agg_emb_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XDpxmVCD-Dso"
      },
      "outputs": [],
      "source": [
        "agg_emb_df = agg_emb_df.sort_values('timestamp')\n",
        "time_list = agg_emb_df['timestamp'].values\n",
        "ext_embeddings = agg_emb_df['mean_embedding'].values\n",
        "ext_embeddings = np.stack(ext_embeddings)\n",
        "\n",
        "external_features = time_list, ext_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIu3CduTw8im",
        "outputId": "8fab7587-886b-4946-8c30-f1d686265d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Все слои сети заморожены.\n"
          ]
        }
      ],
      "source": [
        "model.add_external_features(external_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HfQO5umSw5tP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 38/38 [00:11<00:00,  3.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 5.1625, Val NDCG@10: 0.0139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 38/38 [00:10<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 2.9256, Val NDCG@10: 0.0315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 38/38 [00:07<00:00,  5.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 2.7627, Val NDCG@10: 0.0439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 38/38 [00:13<00:00,  2.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 2.6704, Val NDCG@10: 0.0512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 38/38 [00:12<00:00,  2.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 2.6123, Val NDCG@10: 0.0556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 38/38 [00:21<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 2.5680, Val NDCG@10: 0.0610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 38/38 [00:18<00:00,  2.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 2.5357, Val NDCG@10: 0.0641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 38/38 [00:15<00:00,  2.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 2.5169, Val NDCG@10: 0.0642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 38/38 [00:08<00:00,  4.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 2.4989, Val NDCG@10: 0.0662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 38/38 [00:16<00:00,  2.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 2.4822, Val NDCG@10: 0.0654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 38/38 [00:15<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Loss: 2.4702, Val NDCG@10: 0.0669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 38/38 [00:12<00:00,  3.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Loss: 2.4628, Val NDCG@10: 0.0656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20: 100%|██████████| 38/38 [00:10<00:00,  3.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Loss: 2.4538, Val NDCG@10: 0.0654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20: 100%|██████████| 38/38 [00:11<00:00,  3.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Loss: 2.4450, Val NDCG@10: 0.0673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20: 100%|██████████| 38/38 [00:11<00:00,  3.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Loss: 2.4376, Val NDCG@10: 0.0646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20: 100%|██████████| 38/38 [00:06<00:00,  6.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Loss: 2.4300, Val NDCG@10: 0.0661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20: 100%|██████████| 38/38 [00:11<00:00,  3.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Loss: 2.4302, Val NDCG@10: 0.0674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20: 100%|██████████| 38/38 [00:13<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Loss: 2.4238, Val NDCG@10: 0.0640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20: 100%|██████████| 38/38 [00:20<00:00,  1.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Loss: 2.4204, Val NDCG@10: 0.0659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20: 100%|██████████| 38/38 [00:16<00:00,  2.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Loss: 2.4162, Val NDCG@10: 0.0660\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = train_sasrec(model, train_loader, val_loader, optimizer, criterion, device, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ykpb7Yv_DsIV",
        "outputId": "fadf10a2-b6b6-4441-8a36-07fc535c312d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размороженные параметры: ['ext_head.weight', 'ext_head.bias']\n"
          ]
        }
      ],
      "source": [
        "def check_unfrozen_params(model):\n",
        "    unfrozen_params = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            unfrozen_params.append(name)\n",
        "    return unfrozen_params\n",
        "\n",
        "print(\"Размороженные параметры:\", check_unfrozen_params(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxvaU3k1w6Fc"
      },
      "source": [
        "# Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8nw-erdinkJD"
      },
      "outputs": [],
      "source": [
        "# Добавляем расчет NDCG для бустинга\n",
        "def calculate_ndcg_for_boosting(model, X, y, user_ids, k=10):\n",
        "    \"\"\"\n",
        "    Вычисляет NDCG@k для модели бустинга, группируя предсказания по пользователям\n",
        "    \"\"\"\n",
        "    # Получаем предсказания модели\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    # Создаем DataFrame с user_id, предсказаниями и истинными значениями\n",
        "    results_df = pd.DataFrame({\n",
        "        'user_id': user_ids,\n",
        "        'prediction': predictions,\n",
        "        'true_rating': y\n",
        "    })\n",
        "\n",
        "    # Группируем по пользователям\n",
        "    ndcg_scores = []\n",
        "    for user_id, group in results_df.groupby('user_id'):\n",
        "        if len(group) < 2:\n",
        "            continue  # Пропускаем пользователей с менее чем 2 взаимодействиями\n",
        "\n",
        "        # Сортируем предсказания и истинные значения\n",
        "        pred_sorted = group.sort_values('prediction', ascending=False)['true_rating'].values\n",
        "        true_sorted = group.sort_values('true_rating', ascending=False)['true_rating'].values\n",
        "\n",
        "        # Вычисляем NDCG\n",
        "        ndcg = ndcg_score([true_sorted], [pred_sorted], k=k)\n",
        "        ndcg_scores.append(ndcg)\n",
        "\n",
        "    return np.mean(ndcg_scores) if ndcg_scores else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNUOQm8dnms4",
        "outputId": "8fa5b4ee-a5bf-40a8-a2cc-dccf0839f983"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preparing boosting data:   0%|          | 0/6038 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preparing boosting data: 100%|██████████| 6038/6038 [1:52:45<00:00,  1.12s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LightGBM model...\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006820 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 32621\n",
            "[LightGBM] [Info] Number of data points in the train set: 47430, number of used features: 128\n",
            "[LightGBM] [Info] Start training from score 4.391777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ext_recsys/miniconda/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/home/ext_recsys/miniconda/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 128)) while a minimum of 1 is required by LGBMRegressor.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_20618/3875159157.py\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Оцениваем модель с помощью RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mtrain_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda/lib/python3.9/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLGBMNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Estimator not fitted, call fit before exploiting the model.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_DataTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             X = _LGBMValidateData(\n\u001b[0m\u001b[1;32m   1109\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 128)) while a minimum of 1 is required by LGBMRegressor."
          ]
        }
      ],
      "source": [
        "boost_data = []\n",
        "boost_labels = []\n",
        "boost_user_ids = []  # Для хранения ID пользователей\n",
        "boost_timestamps = []  # Для хранения временных меток\n",
        "\n",
        "add_external = False\n",
        "\n",
        "with torch.no_grad():\n",
        "    for user_id in tqdm(ratings[\"user_id\"].unique(), desc=\"Preparing boosting data\"):\n",
        "        user_data = subset_data[subset_data['user_id'] == user_id]\n",
        "        user_items = user_data['item_id'].tolist()\n",
        "        user_ratings = user_data['rating'].tolist()\n",
        "        user_timestamps = user_data['timestamp'].tolist()\n",
        "\n",
        "        for i in range(1, len(user_items)):\n",
        "            # Получаем эмбеддинг пользователя\n",
        "            seq = user_items[:i]\n",
        "            if len(seq) > model.max_len:\n",
        "                seq = seq[-model.max_len:]\n",
        "            else:\n",
        "                seq = [0] * (model.max_len - len(seq)) + seq\n",
        "\n",
        "            input_seq = torch.tensor([seq], dtype=torch.long).to(device)\n",
        "            user_embedding = model.get_embeddings(input_seq)[0, -1, :].cpu().numpy()\n",
        "\n",
        "            # Получаем эмбеддинг айтема\n",
        "            item_id = user_items[i]\n",
        "            item_embedding = model.item_emb(torch.tensor([item_id], dtype=torch.long).to(device))[0].cpu().numpy()\n",
        "\n",
        "            # Получаем агрегированный эмбеддинг контекста\n",
        "            timestamp = user_data.iloc[i-1]['timestamp']\n",
        "            meta_features = np.array([user_id, item_id, timestamp])\n",
        "            n_meta_features = len(meta_features)\n",
        "\n",
        "            if add_external:\n",
        "                context_info = agg_emb_df[agg_emb_df['timestamp'] <= timestamp].iloc[-1]\n",
        "                mean_context = context_info['mean_embedding']\n",
        "                max_context = context_info['max_embedding']\n",
        "\n",
        "                # Объединяем все эмбеддинги\n",
        "                combined_features = np.concatenate([meta_features, user_embedding, mean_context, max_context, item_embedding])\n",
        "            else:\n",
        "                combined_features = np.concatenate([meta_features, user_embedding, item_embedding]) #mean_context, max_context, ])\n",
        "\n",
        "            boost_data.append(combined_features)\n",
        "            boost_labels.append(user_ratings[i])\n",
        "            boost_user_ids.append(user_id)\n",
        "            boost_timestamps.append(user_timestamps[i])\n",
        "\n",
        "# Преобразуем в numpy массивы\n",
        "X = np.array(boost_data)\n",
        "y = np.array(boost_labels)\n",
        "user_ids = np.array(boost_user_ids)\n",
        "train_users_boost = np.array([data[0] in train_users for data in X])\n",
        "\n",
        "# Разделяем на train/test\n",
        "# split_idx = int(0.8 * len(X))\n",
        "X_train, X_test = X[train_users_boost, n_meta_features:], X[~train_users_boost, n_meta_features:]\n",
        "y_train, y_test = y[train_users_boost], y[~train_users_boost]\n",
        "user_ids_train, user_ids_test = user_ids[train_users_boost], user_ids[~train_users_boost]\n",
        "\n",
        "# Обучаем модель бустинга\n",
        "print(\"Training LightGBM model...\")\n",
        "lgb_model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.05)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Оцениваем модель с помощью RMSE\n",
        "train_pred = lgb_model.predict(X_train)\n",
        "test_pred = lgb_model.predict(X_test)\n",
        "\n",
        "train_rmse = np.sqrt(np.mean((train_pred - y_train) ** 2))\n",
        "test_rmse = np.sqrt(np.mean((test_pred - y_test) ** 2))\n",
        "\n",
        "print(f\"LightGBM Train RMSE: {train_rmse:.4f}\")\n",
        "print(f\"LightGBM Test RMSE: {test_rmse:.4f}\")\n",
        "\n",
        "# Оцениваем модель с помощью NDCG\n",
        "train_ndcg = calculate_ndcg_for_boosting(lgb_model, X_train, y_train, user_ids_train, k=10)\n",
        "test_ndcg = calculate_ndcg_for_boosting(lgb_model, X_test, y_test, user_ids_test, k=10)\n",
        "\n",
        "print(f\"LightGBM Train NDCG@10: {train_ndcg:.4f}\")\n",
        "print(f\"LightGBM Test NDCG@10: {test_ndcg:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynbrLdTLnqp1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
